# Detecting different types of toxicity in comments.
Models: LSTM, GRU, CNN-LSTM, BiLSTM

# Dataset
https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge

# LSTM
Accuracy:	96.28%
<img src="Models/LSTM.png"/>

# GRU
Accuracy:	96.25%
<img src="Models/GRU.png"/>

# CNN-LSTM
Accuracy:	96.30%
<img src="Models/CNN-LSTM.png"/>

# BiLSTM
Accuracy:	96.27%
<img src="Models/BiLSTM.png"/>
